{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes\n",
    "from imp import reload\n",
    "import feedparser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOPosts, listClasses = bayes.loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myVocabList = bayes.createVocabList(listOPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'is',\n",
       " 'my',\n",
       " 'park',\n",
       " 'has',\n",
       " 'so',\n",
       " 'problems',\n",
       " 'garbage',\n",
       " 'food',\n",
       " 'quit',\n",
       " 'help',\n",
       " 'flea',\n",
       " 'dalmation',\n",
       " 'worthless',\n",
       " 'licks',\n",
       " 'stop',\n",
       " 'dog',\n",
       " 'mr',\n",
       " 'not',\n",
       " 'stupid',\n",
       " 'maybe',\n",
       " 'ate',\n",
       " 'how',\n",
       " 'posting',\n",
       " 'steak',\n",
       " 'buying',\n",
       " 'cute',\n",
       " 'please',\n",
       " 'him',\n",
       " 'take',\n",
       " 'I',\n",
       " 'love']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myVocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.setOfWords2Vec(myVocabList, listOPosts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.setOfWords2Vec(myVocabList, listOPosts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOPosts, listClasses = bayes.loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "myVocabList = bayes.createVocabList(listOPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(bayes.setOfWords2Vec(myVocabList, postinDoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0V, p1V, pAb = bayes.trainNB0(trainMat, listClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pAb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -1.8718021769015913,\n",
       " -3.258096538021482,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -3.258096538021482,\n",
       " -3.258096538021482,\n",
       " -3.258096538021482,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -3.258096538021482,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -3.258096538021482,\n",
       " -3.258096538021482,\n",
       " -3.258096538021482,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -3.258096538021482,\n",
       " -2.5649493574615367,\n",
       " -3.258096538021482,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367,\n",
       " -2.159484249353372,\n",
       " -3.258096538021482,\n",
       " -2.5649493574615367,\n",
       " -2.5649493574615367]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.3513752571634776,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423,\n",
       " -2.3513752571634776,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423,\n",
       " -2.3513752571634776,\n",
       " -2.3513752571634776,\n",
       " -2.3513752571634776,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423,\n",
       " -1.9459101490553135,\n",
       " -3.044522437723423,\n",
       " -2.3513752571634776,\n",
       " -1.9459101490553135,\n",
       " -3.044522437723423,\n",
       " -2.3513752571634776,\n",
       " -1.6582280766035324,\n",
       " -2.3513752571634776,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423,\n",
       " -2.3513752571634776,\n",
       " -3.044522437723423,\n",
       " -2.3513752571634776,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423,\n",
       " -2.3513752571634776,\n",
       " -2.3513752571634776,\n",
       " -3.044522437723423,\n",
       " -3.044522437723423]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'my', 'dalmation'] classified as:  0\n",
      "['stupid', 'garbage'] classified as:  1\n"
     ]
    }
   ],
   "source": [
    "bayes.testingNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySent = 'This book is the best book on Python or M.L. I have ever laid eyes upon.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'M.L.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regEx = re.compile('\\\\W+')# python 3 '+' 替换 ‘*’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfTokens = regEx.split(mySent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'M',\n",
       " 'L',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon',\n",
       " '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'M',\n",
       " 'L',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok for tok in listOfTokens if len(tok) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'm',\n",
       " 'l',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.lower() for tok in listOfTokens if len(tok) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailText = open('email/ham/6.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfTokens = regEx.split(emailText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Since',\n",
       " 'you',\n",
       " 'are',\n",
       " 'an',\n",
       " 'owner',\n",
       " 'of',\n",
       " 'at',\n",
       " 'least',\n",
       " 'one',\n",
       " 'Google',\n",
       " 'Groups',\n",
       " 'group',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'the',\n",
       " 'customized',\n",
       " 'welcome',\n",
       " 'message',\n",
       " 'pages',\n",
       " 'or',\n",
       " 'files',\n",
       " 'we',\n",
       " 'are',\n",
       " 'writing',\n",
       " 'to',\n",
       " 'inform',\n",
       " 'you',\n",
       " 'that',\n",
       " 'we',\n",
       " 'will',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'be',\n",
       " 'supporting',\n",
       " 'these',\n",
       " 'features',\n",
       " 'starting',\n",
       " 'February',\n",
       " '2011',\n",
       " 'We',\n",
       " 'made',\n",
       " 'this',\n",
       " 'decision',\n",
       " 'so',\n",
       " 'that',\n",
       " 'we',\n",
       " 'can',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'improving',\n",
       " 'the',\n",
       " 'core',\n",
       " 'functionalities',\n",
       " 'of',\n",
       " 'Google',\n",
       " 'Groups',\n",
       " 'mailing',\n",
       " 'lists',\n",
       " 'and',\n",
       " 'forum',\n",
       " 'discussions',\n",
       " 'Instead',\n",
       " 'of',\n",
       " 'these',\n",
       " 'features',\n",
       " 'we',\n",
       " 'encourage',\n",
       " 'you',\n",
       " 'to',\n",
       " 'use',\n",
       " 'products',\n",
       " 'that',\n",
       " 'are',\n",
       " 'designed',\n",
       " 'specifically',\n",
       " 'for',\n",
       " 'file',\n",
       " 'storage',\n",
       " 'and',\n",
       " 'page',\n",
       " 'creation',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Google',\n",
       " 'Docs',\n",
       " 'and',\n",
       " 'Google',\n",
       " 'Sites',\n",
       " 'For',\n",
       " 'example',\n",
       " 'you',\n",
       " 'can',\n",
       " 'easily',\n",
       " 'create',\n",
       " 'your',\n",
       " 'pages',\n",
       " 'on',\n",
       " 'Google',\n",
       " 'Sites',\n",
       " 'and',\n",
       " 'share',\n",
       " 'the',\n",
       " 'site',\n",
       " 'http',\n",
       " 'www',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'sites',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '174623',\n",
       " 'with',\n",
       " 'the',\n",
       " 'members',\n",
       " 'of',\n",
       " 'your',\n",
       " 'group',\n",
       " 'You',\n",
       " 'can',\n",
       " 'also',\n",
       " 'store',\n",
       " 'your',\n",
       " 'files',\n",
       " 'on',\n",
       " 'the',\n",
       " 'site',\n",
       " 'by',\n",
       " 'attaching',\n",
       " 'files',\n",
       " 'to',\n",
       " 'pages',\n",
       " 'http',\n",
       " 'www',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'sites',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '90563',\n",
       " 'on',\n",
       " 'the',\n",
       " 'site',\n",
       " 'If',\n",
       " 'you抮e',\n",
       " 'just',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'a',\n",
       " 'place',\n",
       " 'to',\n",
       " 'upload',\n",
       " 'your',\n",
       " 'files',\n",
       " 'so',\n",
       " 'that',\n",
       " 'your',\n",
       " 'group',\n",
       " 'members',\n",
       " 'can',\n",
       " 'download',\n",
       " 'them',\n",
       " 'we',\n",
       " 'suggest',\n",
       " 'you',\n",
       " 'try',\n",
       " 'Google',\n",
       " 'Docs',\n",
       " 'You',\n",
       " 'can',\n",
       " 'upload',\n",
       " 'files',\n",
       " 'http',\n",
       " 'docs',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '50092',\n",
       " 'and',\n",
       " 'share',\n",
       " 'access',\n",
       " 'with',\n",
       " 'either',\n",
       " 'a',\n",
       " 'group',\n",
       " 'http',\n",
       " 'docs',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '66343',\n",
       " 'or',\n",
       " 'an',\n",
       " 'individual',\n",
       " 'http',\n",
       " 'docs',\n",
       " 'google',\n",
       " 'com',\n",
       " 'support',\n",
       " 'bin',\n",
       " 'answer',\n",
       " 'py',\n",
       " 'hl',\n",
       " 'en',\n",
       " 'answer',\n",
       " '86152',\n",
       " 'assigning',\n",
       " 'either',\n",
       " 'edit',\n",
       " 'or',\n",
       " 'download',\n",
       " 'only',\n",
       " 'access',\n",
       " 'to',\n",
       " 'the',\n",
       " 'files',\n",
       " 'you',\n",
       " 'have',\n",
       " 'received',\n",
       " 'this',\n",
       " 'mandatory',\n",
       " 'email',\n",
       " 'service',\n",
       " 'announcement',\n",
       " 'to',\n",
       " 'update',\n",
       " 'you',\n",
       " 'about',\n",
       " 'important',\n",
       " 'changes',\n",
       " 'to',\n",
       " 'Google',\n",
       " 'Groups',\n",
       " '']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate is:  0.2\n"
     ]
    }
   ],
   "source": [
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = feedparser.parse('http://www.nasa.gov/rss/dyn/image_of_the_day.rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = feedparser.parse('http://www.cppblog.com/kevinlynx/category/6337.html/rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate is:  0.55\n"
     ]
    }
   ],
   "source": [
    "vocabList, pSF, pNY = bayes.localWords(ny, sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate is:  0.6\n"
     ]
    }
   ],
   "source": [
    "vocabList, pSF, pNY = bayes.localWords(ny, sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate is:  0.45\n",
      "SF**SF**SF**SF**SF**SF**SF\n",
      "cccccc\n",
      "right\n",
      "4px\n",
      "amp\n",
      "bottom\n",
      "highlight\n",
      "808080\n",
      "inline\n",
      "void\n",
      "left\n",
      "int\n",
      "codemacro\n",
      "return\n",
      "kevinlynx\n",
      "define\n",
      "strong\n",
      "background\n",
      "break\n",
      "this\n",
      "width\n",
      "xff0c\n",
      "x7684\n",
      "_z13getstacktraceppvii\n",
      "item\n",
      "onclick\n",
      "html\n",
      "target\n",
      "typename\n",
      "_blank\n",
      "gdb\n",
      "dtv\n",
      "the\n",
      "pred\n",
      "decoration\n",
      "pointer\n",
      "text\n",
      "13px\n",
      "5px\n",
      "eeeeee\n",
      "inblock\n",
      "lynx\n",
      "kevin\n",
      "data\n",
      "const\n",
      "008000\n",
      "char\n",
      "word\n",
      "all\n",
      "language\n",
      "mov\n",
      "next\n",
      "blockquote\n",
      "x3002\n",
      "for\n",
      "public\n",
      "lang\n",
      "rbp\n",
      "node_t\n",
      "dec\n",
      "NY**NY**NY**NY**NY**NY**NY\n",
      "the\n",
      "this\n",
      "nasa\n",
      "and\n",
      "from\n",
      "space\n",
      "image\n",
      "international\n",
      "station\n",
      "view\n",
      "that\n",
      "taken\n",
      "april\n",
      "astronaut\n",
      "were\n",
      "our\n",
      "2018\n",
      "with\n",
      "was\n",
      "are\n",
      "earth\n",
      "could\n",
      "like\n",
      "for\n",
      "years\n",
      "rocket\n",
      "mars\n",
      "mount\n",
      "memphis\n",
      "stellar\n",
      "black\n",
      "islands\n",
      "light\n",
      "park\n",
      "national\n",
      "northern\n",
      "march\n",
      "time\n",
      "part\n",
      "these\n",
      "launched\n",
      "ricky\n",
      "arnold\n",
      "large\n",
      "captured\n",
      "before\n",
      "been\n",
      "seemingly\n",
      "base\n",
      "astrotech\n",
      "everyone\n",
      "search\n",
      "martin\n",
      "sharing\n",
      "collapsing\n",
      "luther\n",
      "there\n",
      "resolution\n",
      "they\n",
      "sky\n",
      "famous\n",
      "warps\n",
      "mosaic\n",
      "many\n",
      "printed\n",
      "outside\n",
      "not\n",
      "gullies\n",
      "stimulate\n",
      "successfully\n",
      "detailed\n",
      "transiting\n",
      "make\n",
      "day\n",
      "legacy\n",
      "galápagos\n",
      "hand\n",
      "heat\n",
      "running\n",
      "spacecraft\n",
      "vandenberg\n",
      "aug\n",
      "universe\n",
      "republic\n",
      "embedded\n",
      "saturn\n",
      "observatory\n",
      "feustel\n",
      "support\n",
      "ahead\n",
      "those\n",
      "taped\n",
      "galaxies\n",
      "stitch\n",
      "lights\n",
      "off\n",
      "martian\n",
      "board\n",
      "giving\n",
      "ten\n",
      "king\n",
      "captures\n",
      "high\n",
      "mission\n",
      "force\n",
      "infant\n",
      "crater\n",
      "ngc\n",
      "celebrates\n",
      "over\n",
      "atoll\n",
      "have\n",
      "using\n",
      "computers\n",
      "supersonic\n",
      "magnetic\n",
      "ones\n",
      "gas\n",
      "city\n",
      "followers\n",
      "life\n",
      "real\n",
      "window\n",
      "1968\n",
      "low\n",
      "radiation\n",
      "storm\n",
      "cloud\n",
      "satellite\n",
      "sharp\n",
      "sun\n",
      "survey\n",
      "three\n",
      "innovations\n",
      "orbiting\n",
      "exploration\n",
      "destruction\n",
      "night\n",
      "lucky\n",
      "seat\n",
      "reducing\n",
      "anniversary\n",
      "while\n",
      "stream\n",
      "sounding\n",
      "may\n",
      "hangs\n",
      "curiosity\n",
      "step\n",
      "telescope\n",
      "its\n",
      "industry\n",
      "seismic\n",
      "cosmic\n",
      "software\n",
      "borealis\n",
      "photographed\n",
      "lander\n",
      "government\n",
      "landing\n",
      "digital\n",
      "processing\n",
      "hemisphere\n",
      "extremely\n",
      "brant\n",
      "tennessee\n",
      "translunar\n",
      "steady\n",
      "heavens\n",
      "birth\n",
      "1972\n",
      "28th\n",
      "marshall\n",
      "planets\n",
      "ecuador\n",
      "celebrate\n",
      "soyuz\n",
      "star\n",
      "close\n",
      "their\n",
      "travel\n",
      "air\n",
      "launch\n",
      "shows\n",
      "underlying\n",
      "nearest\n",
      "galaxy\n",
      "inside\n",
      "aboard\n",
      "fifty\n",
      "tli\n",
      "arcs\n",
      "billie\n",
      "place\n",
      "local\n",
      "transport\n",
      "orbit\n",
      "solar\n",
      "wednesday\n",
      "hubble\n",
      "energetic\n",
      "tested\n",
      "next\n",
      "mass\n",
      "flows\n",
      "particles\n",
      "active\n",
      "nov\n",
      "edt\n",
      "kwajalein\n",
      "who\n",
      "graceful\n",
      "einstein\n",
      "paper\n",
      "collect\n",
      "clear\n",
      "atmosphere\n",
      "land\n",
      "chess\n",
      "colorado\n",
      "known\n",
      "population\n",
      "including\n",
      "uphill\n",
      "colorful\n",
      "trimmed\n",
      "gets\n",
      "simulation\n",
      "investigations\n",
      "looks\n",
      "flight\n",
      "mathematician\n",
      "bringing\n",
      "can\n",
      "enchanted\n",
      "dramatically\n",
      "injection\n",
      "distant\n",
      "system\n",
      "honor\n",
      "but\n",
      "ring\n",
      "mountaintop\n",
      "aeronautical\n",
      "bright\n",
      "robertson\n",
      "spacewalk\n",
      "geodesy\n",
      "lunar\n",
      "delivered\n",
      "rings\n",
      "apollo\n",
      "nebula\n",
      "speech\n",
      "his\n",
      "subtle\n",
      "insight\n",
      "created\n",
      "dunes\n",
      "history\n",
      "fields\n",
      "phenomenon\n",
      "still\n",
      "possible\n",
      "jupiter\n",
      "gravitationally\n",
      "orbited\n",
      "last\n",
      "tapestry\n",
      "crewmembers\n",
      "she\n",
      "extraordinary\n",
      "colors\n",
      "rover\n",
      "cluster\n",
      "346\n",
      "tess\n",
      "states\n",
      "2009\n",
      "scheduled\n",
      "stars\n",
      "together\n",
      "ago\n",
      "around\n",
      "rainier\n",
      "exoplanet\n",
      "become\n",
      "cassini\n",
      "data\n",
      "sand\n",
      "photo\n",
      "facility\n",
      "partnership\n",
      "clouds\n",
      "tops\n",
      "viewing\n",
      "assassinated\n",
      "one\n",
      "aurora\n",
      "week\n",
      "spectrograph\n",
      "forming\n",
      "echelle\n",
      "new\n",
      "conducting\n",
      "above\n",
      "interior\n",
      "very\n",
      "bathes\n",
      "united\n",
      "matara\n",
      "drew\n"
     ]
    }
   ],
   "source": [
    "bayes.getTopWords(ny, sf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
